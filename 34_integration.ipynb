{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Foundations of Computational Economics #34\n",
    "\n",
    "by Fedor Iskhakov, ANU\n",
    "\n",
    "<img src=\"_static/img/dag3logo.png\" style=\"width:256px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Numerical integration, quadrature\n",
    "\n",
    "<img src=\"_static/img/lecture.png\" style=\"width:64px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"_static/img/youtube.png\" style=\"width:65px;\">\n",
    "\n",
    "[https://youtu.be/cc14S679x2M](https://youtu.be/cc14S679x2M)\n",
    "\n",
    "Description: Gaussian quadrature. Monte Carlo integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Integration in economics\n",
    "\n",
    "- Expected (discounted) utility  \n",
    "- Expected (discounted) profits  \n",
    "- Bayesian posterior  \n",
    "- Likelihood function with unobservables  \n",
    "- Stochastic elements in (dynamic) economic models  \n",
    "\n",
    "\n",
    "*Most integrals can not be evaluated analytically*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Two main approaches: Monte Carlo and quadrature\n",
    "\n",
    "1. Based on simulations – **Monte Carlo integration**  \n",
    "1. Based on the fixed points and weights – **quadrature integration**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Newton-Cotes formulas\n",
    "\n",
    "Goal: definite integral $ \\int_a^b f(x) dx $\n",
    "\n",
    "Idea: Approximate the function with low order polynomial, then integrate\n",
    "approximation\n",
    "\n",
    "1. First order >> Step function approximation  \n",
    "  - Constant, level at midpoint of $ [a,b] $  \n",
    "1. Second order >> Linear approximation  \n",
    "  - Trapezoid rule  \n",
    "1. Third order >> Quadratic approximation  \n",
    "  - Simpson rule  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/img/composite_simpsons.png\" style=\"width:800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Composite Newton-Cotes\n",
    "\n",
    "Preform Newton-Cotes on a grid separately on each interval\n",
    "\n",
    "- Equally spaced points  \n",
    "- Newton-Cotes on each sub-interval  \n",
    "\n",
    "\n",
    "*Note that the points are placed exogenously*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/img/newton-cotes.jpg\" style=\"width:800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian quadrature\n",
    "\n",
    "General formula\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x) dx = \\sum_{i=1}^n \\omega_i f(x_i)\n",
    "$$\n",
    "\n",
    "- $ x_i \\in [a,b] $ quadrature nodes  \n",
    "- $ \\omega_i $ quadrature weights  \n",
    "\n",
    "\n",
    "*Note that the points are placed endogenously*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quadrature accuracy\n",
    "\n",
    "Suppose that $ \\{\\phi_k(x)\\}_{k=1,2,\\dots} $ is family of\n",
    "polynomials of degree $ k $ *orthogonal* with respect to the\n",
    "weighting function $ w(x) $\n",
    "\n",
    "- let $ q_k $ denote the leading coefficients so that $ \\phi_k(x)=q_k x^k + \\dots $  \n",
    "- let $ x_i $, $ i=1,\\dots,n $ be $ n $ roots of $ \\phi_n(x) $  \n",
    "- let $ \\omega_i = - \\frac{q_{n+1}/q_n}{\\phi'_n(x_i)\\phi_{n+1}(x_i)}>0 $  \n",
    "\n",
    "\n",
    "Then\n",
    "\n",
    "- $ a<x_1<x_2<\\dots<x_n<b $  \n",
    "- for $ f(x) \\in C^{(2n)}[a,b] $, for some $ \\xi\\in[a,b] $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_a^b w(x) f(x) dx = \\sum_{i=1}^n \\omega_i f(x_i) + \\frac{f^{(2n)}(\\xi)}{q_n^2(2n)!}\n",
    "$$\n",
    "\n",
    "- the right hand side is unique on $ n $ nodes  \n",
    "- exact integral for all polynomial $ f(x) $ of degree $ 2n-1 $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Chebyshev Quadrature\n",
    "\n",
    "- Domain $ [-1,1] $  \n",
    "- Weighting function $ (1-x^2)^{(-1/2)} $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{-1}^1 \\frac{f(x)dx}{\\sqrt{1-x^2}} = \\frac{\\pi}{n}\\sum_{i=1}^{n} f(x_i) + \\frac{\\pi}{2^{2n-1}}\\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "- quadrature nodes $ x_i = \\cos(\\frac{2i-1}{2n}\\pi) $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Want to integrate $ f(x) $ on $ [a,b] $, no weighting function.\n",
    "1. Change of variable $ y=2(x-a)/(b-a)-1 $\n",
    "2. Multiply and divide by weighting function\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)dx = \\frac{b-a}{2}\\int_{-1}^{1}f\\big(\\frac{(y+1)(b-a)}{2}+a\\big)\\frac{\\sqrt{1-y^2}}{\\sqrt{1-y^2}}dy\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)dx = \\frac{\\pi(b-a)}{2n}\\sum_{i=1}^{n}f\\big(\\frac{(y_i+1)(b-a)}{2}+a\\big)\\sqrt{1-y_i^2}\n",
    "$$\n",
    "\n",
    "where $ y_i $ are Gauss-Chebyshev nodes over $ [-1,1] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Legendre Quadrature\n",
    "\n",
    "- Domain $ [-1,1] $  \n",
    "- Weighting function $ 1 $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{-1}^1 f(x)dx = \\sum_{i=1}^{n} \\omega_i f(x_i) + \\frac{2^{2n+1}(n!)^4}{(2n+1)!(2n)!} \\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "- Nodes and weights come from Legendre polynomials, values tabulated  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Hermite Quadrature\n",
    "\n",
    "- Domain $ [-\\infty,\\infty] $  \n",
    "- Weighting function $ \\exp(-x^2) $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^\\infty f(x) \\exp(-x^2)dx = \\sum_{i=1}^{n} \\omega_i f(x_i) + \\frac{n!\\sqrt{\\pi}}{2^n}\\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "- Nodes and weights come from Hermite polynomials, values tabulated  \n",
    "- Good for computing expectation with Normal distribution  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gauss-Laguerre Quadrature\n",
    "\n",
    "- Domain $ [0,\\infty] $  \n",
    "- Weighting function $ \\exp(-x) $  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{0}^\\infty f(x) \\exp(-x)dx = \\sum_{i=1}^{n} \\omega_i f(x_i) + (n!)^2\\frac{f^{(2n)}(\\xi)}{(2n)!}\n",
    "$$\n",
    "\n",
    "- Nodes and weights come from Laguerre polynomials, values tabulated  \n",
    "- Good for computing expectation exponential discounting  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multidimensional quadrature\n",
    "\n",
    "Much more complication, simple methods are subject to curse of\n",
    "dimensionality\n",
    "\n",
    "- Generic product rule  \n",
    "\n",
    "\n",
    "$$\n",
    "\\int_{[a,b]^d}f(x)dx=\\sum_{i_1=1}^n \\dots\\sum_{i_d=1}^n \\omega_{i_1}^1\\dots\\omega_{i_1}^d f(x_{i_1}^1,\\dots,x^d_{i_d})\n",
    "$$\n",
    "\n",
    "- Product Gaussian quadrature based on product orthogonal polynomials  \n",
    "- Sparse methods  \n",
    "- Monte Carlo integration!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monte Carlo integration\n",
    "\n",
    "- Stochastic algorithm for computing integrals  \n",
    "- Main idea: approximate the expectation of a function with an average computed from a sample of random draws  \n",
    "- (convergence in the number of draws is due to the law of large numbers)  \n",
    "- Then convert the integral in expectation to the integral of interest  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expectation of a function of random variable\n",
    "\n",
    "- let continuous random variable $ \\tilde{X} $ be distributed with pdf $ p(x) $ over domain $ \\Omega $  \n",
    "- we are interested in the expectation of the function $ f(\\tilde{X}) $ which is in turn a random variable itself  \n",
    "\n",
    "\n",
    "$$\n",
    "E\\big(f(\\tilde{X})\\big) = \\int_{\\Omega} f(x) \\,dF(x) = \\int_{\\Omega} f(x) p(x) \\,dx\n",
    "$$\n",
    "\n",
    "- variance of $ f(\\tilde{X}) $ is  \n",
    "\n",
    "\n",
    "$$\n",
    "\\operatorname{Var} \\big(f(\\tilde{X})\\big) = E\\Big(f(\\tilde{X})- E\\big(f(\\tilde{X})\\big)\\Big)^2 = E\\big(f(\\tilde{X})\\big)^2 - \\Big(E\\big(f(\\tilde{X})\\big)\\Big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From expectation to integration\n",
    "\n",
    "- imagine we want to compute the integral denoted $ I_f $ of function $ f(x) $ over some set $ \\Omega $  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f =\\int_{\\Omega} f(x)\\,dx\n",
    "$$\n",
    "\n",
    "- Step 1: represent the integral as an expectation of a function of some random variable $ \\tilde{X} $ defined over domain $ \\Omega $  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f =\\int_{\\Omega} f(x)\\,dx =\n",
    "\\int_{\\Omega} \\frac{f(x)}{p(x)} p(x) \\,dx =E \\left[ \\frac{f(\\tilde{X})}{p(\\tilde{X})} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From expectation to integration\n",
    "\n",
    "- Step 2: compute the expectation using $ N $ independent draws $ x_i $ of $ \\tilde{X} $ — from the distribution with pdf $ p(x) $  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f =\\int_{\\Omega} f(x)\\,dx = E \\left[ \\frac{f(\\tilde{X})}{p(\\tilde{X})} \\right] \\approx \\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(x_i)}{p(x_i)}\n",
    "\\underset{N \\rightarrow \\infty}{\\rightarrow} E \\left[ \\frac{f(\\tilde{X})}{p(\\tilde{X})} \\right]\n",
    "$$\n",
    "\n",
    "- convergence due to the law of large numbers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Special simple case (naive Monte Carlo integration)\n",
    "\n",
    "- not to have to deal with pdf $ p(x) $ we can use **uniform distribution**  \n",
    "- then pdf $ p(x) $ is independent of $ x $ and can be treated as a constant  \n",
    "\n",
    "\n",
    "$$\n",
    "p(x) = \\left( \\int_{\\Omega} dx \\right) ^{-1} = \\frac{1}{V}\n",
    "$$\n",
    "\n",
    "- $ V $ is a measure of the set $ \\Omega $: length in one dimension, volume in two dimensions, etc.  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f =\\int_{\\Omega} f(x)\\,dx = E \\left[ Vf(\\tilde{X}) \\right] \\approx \\frac{V}{N} \\sum_{i=1}^{N} f(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Special even simpler case with unit hypercube\n",
    "\n",
    "- let $ \\Omega \\subset \\mathbb{R}^n $ be a unit hypercube denoted $ H_n $ in $ n $-dimensional space  \n",
    "- then $ V = 1 $  \n",
    "- integral is the same as simple average of the function computed on a random set of points uniformly distributed over the hypercube  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f =\\int_{H_n} f(x)\\,dx  \\approx \\frac{1}{N} \\sum_{i=1}^{N} f(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One dimensional example\n",
    "\n",
    "- let $ \\Omega $ be an interval $ [a,b] \\subset \\mathbb{R} $ in one dimensional space  \n",
    "- then $ V = b-a $  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f =\\int_{a}^{b} f(x)\\,dx  \\approx \\frac{b-a}{N} \\sum_{i=1}^{N} f(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One dimensional example visual\n",
    "\n",
    "<img src=\"_static/img/MCIntegration.png\" style=\"width:1000px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General Monte Carlo integration algorithm\n",
    "\n",
    "1. sample $ N $ points $ x_1,\\cdots,x_N $ from distribution $ p(x) $ of $ \\tilde{X} $ on $ \\Omega $  \n",
    "1. approximate the expectation $ E \\left[ \\frac{f(\\tilde{X})}{p(\\tilde{X})} \\right] $ by the sample average  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f = \\int_{\\Omega} f(x)\\,dx \\approx \\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(x_i)}{p(x_i)} = Q_f(N)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General Monte Carlo integration algorithm (simple naive approach)\n",
    "\n",
    "1. sample $ N $ points $ x_1,\\cdots,x_N $ uniformly on $ \\Omega $  \n",
    "1. approximate the expectation $ E \\left[ V f(\\tilde{X})\\right] $ by the sample average  \n",
    "\n",
    "\n",
    "$$\n",
    "I_f = \\int_{\\Omega} f(x)\\,dx \\approx \\frac{V}{N} \\sum_{i=1}^{N} f(x_i), \\; V =\\int_{\\Omega} \\,dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "def mc_int_cube(f,ndims=1,N=1000):\n",
    "    '''Computes the integral of function f on a hypercube of dimension ndims\n",
    "       using Monte Carlo integration with N uniformly distributed points\n",
    "       Assume function f uses axis=0 for inputs, and can be vectorized in other axis\n",
    "       Return: value and standard error\n",
    "    '''\n",
    "    # generate uniform numbers on the hypercube\n",
    "    x = np.random.random(ndims*N).reshape(ndims,N)  # uniform random numbers in a matrix\n",
    "    y = f(x)                   # function value\n",
    "    Q = y.mean()               # sample average\n",
    "    seQ = y.std()/np.sqrt(N)   # standard error of sample average\n",
    "    return Q,seQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# pi example from video 33 as two-dim integral\n",
    "# Approximate pi using 2-d Monte Carlo integration\n",
    "\n",
    "N=1000 # Number of Monte carlo Samples\n",
    "g = lambda x: (x[0,:]**2 + x[1,:]**2)<1  # indicator function to inegrate\n",
    "\n",
    "q,se = mc_int_cube(g,ndims=2,N=N)\n",
    "pi_hat = 4*q\n",
    "se_pi_hat = 4*se\n",
    "\n",
    "print('Number of Monte Carlo samples   : ', N);\n",
    "print('Estimate (pi_hat)               : ', pi_hat.round(10));\n",
    "print('Standard error (pi_hat)         : ', se_pi_hat.round(10));\n",
    "print('Approximation error (pi_hat-pi) : ', (pi_hat-np.pi).round(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Properties of Monte Carlo integral\n",
    "\n",
    "**Consistency**: Law of large numbers ensures that the sample average converge to the mean\n",
    "\n",
    "$$\n",
    "\\lim _{{N\\to \\infty }}Q_f(N)\n",
    "=\\lim _{{N\\to \\infty }}{\\frac{1}{N}}\\sum _{{i=1}}^{N}\\frac{f(x_i)}{p(x_i)}\n",
    "=E\\left[\\frac{f(\\tilde{x})}{p(\\tilde{x})}\\right] = \\int_{\\Omega} f(x)\\,dx = I_f\n",
    "$$\n",
    "\n",
    "**Assymptotic Normality**: By the central limit theorem we have\n",
    "\n",
    "$$\n",
    "\\sqrt{N}\\left(Q_f(N)-I_f \\right)\\ \\xrightarrow {d} \\ N\\left(0,\\sigma ^{2}\\right), \\; \\sigma^2= \\operatorname{Var}\\left[\\frac{f(\\tilde{x})}{p(\\tilde{x})}\\right]\n",
    "$$\n",
    "\n",
    "The standard error of $ Q_f(N) $ is then given by $ \\sigma_{Q_f(N)}=\\sigma \\big/ \\sqrt{N} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard error of Monte Carlo integral\n",
    "\n",
    "Given our estimate $ Q_f(N) $ of $ I_f $, we can obtain an unbiased estimate of $ \\sigma^2= \\operatorname{Var}\\left[\\frac{f(\\tilde{x})}{p(\\tilde{x})}\\right] $\n",
    "\n",
    "$$\n",
    "{\\hat{\\sigma}}^2_N=\\frac{1}{N-1}\\sum _{i=1}^N \\left(\\frac{f(x_i)}{p(x_i)}-Q_f(N)\\right)^2\n",
    "$$\n",
    "\n",
    "and the estimate of the standard error of $ Q_f(N) $\n",
    "\n",
    "$$\n",
    "{\\hat{\\sigma}}_{Q_f(N)}={\\hat{\\sigma}}_N   \\big/ \\sqrt{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convergence of Monte Carlo integrals\n",
    "\n",
    "The standard error of $ Q_f(N) $:\n",
    "\n",
    "- is given by $ \\sigma_{Q_f(N)}=\\sigma  \\big/ \\sqrt{N} $  \n",
    "- can be estimated by $ {\\hat{\\sigma}}_{Q_f(N)}={\\hat{\\sigma}}_N   \\big/ \\sqrt{N} $  \n",
    "\n",
    "\n",
    "**Decreases with the standard parametric rate** $ \\sqrt{N} $\n",
    "\n",
    "- doubling of precision requires 4 time as many random points  \n",
    "- but does not depend on the dimensionality of the integral, $ \\Omega $ can be high dimensional  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# distribution of Monte Carlo integral\n",
    "\n",
    "N=1000; # number of Monte Carlo samples used to simulate the integral\n",
    "S=1000; # number of runs to generate the distribution of estimates\n",
    "\n",
    "qs = np.empty(S,dtype=float)\n",
    "ses = np.empty(S,dtype=float)\n",
    "\n",
    "for i in range(S):\n",
    "    q,se = mc_int_cube(g,ndims=2,N=N)\n",
    "    qs[i] = 4*q\n",
    "    ses[i] = 4*se\n",
    "\n",
    "plt.hist(qs,bins=50,range=(np.pi-.2, np.pi+.2))\n",
    "plt.title('Distribution of %d Monte Carlo approximations of pi'%S)\n",
    "\n",
    "print('True value (pi)                  :', np.round(np.pi,10))\n",
    "print('Average estimate across all runs :', qs.mean().round(10))\n",
    "print('Mean bias                        :', np.mean(qs-np.pi).round(10))\n",
    "print('Average std err across all runs  :', ses.mean().round(10))\n",
    "print('Std dev of bias                  :', np.std(qs-np.pi).round(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Further learning resources\n",
    "\n",
    "- SciPy docs [https://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html](https://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html)  \n",
    "- [https://en.wikipedia.org/wiki/Gaussian_quadrature](https://en.wikipedia.org/wiki/Gaussian_quadrature)  \n",
    "- Monte Carlo integration [https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-in-practice/monte-carlo-integration](https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-in-practice/monte-carlo-integration)  \n",
    "- Useful library for Monte Carlo methods [https://chaospy.readthedocs.io/en/master/index.html](https://chaospy.readthedocs.io/en/master/index.html)  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1627474986.6924238,
  "filename": "34_integration.rst",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Foundations of Computational Economics #34"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}