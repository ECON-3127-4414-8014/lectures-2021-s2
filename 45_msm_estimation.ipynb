{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Foundations of Computational Economics #45\n",
    "\n",
    "by Fedor Iskhakov, ANU\n",
    "\n",
    "<img src=\"_static/img/dag3logo.png\" style=\"width:256px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Method of simulated moments for model estimation (MSM)\n",
    "\n",
    "<img src=\"_static/img/lecture.png\" style=\"width:64px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"_static/img/youtube.png\" style=\"width:65px;\">\n",
    "\n",
    "[https://youtu.be/usZVzYanLq0](https://youtu.be/usZVzYanLq0)\n",
    "\n",
    "Description: Using data to inform numerical economic models. Calibration and estimation of economic models. Introduction to method of simulated moments (MSM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What to do with numerical solutions of the economic models?\n",
    "\n",
    "In the second half of this course we learned:\n",
    "\n",
    "- how to write and understand Bellman equations to represent real life choice situations in an economic model  \n",
    "- how to choose an appropriate solution method from the toolbox and solve the model  \n",
    "- how to simulate data given the model solution  \n",
    "\n",
    "\n",
    "What is the next step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Once we know how to solve and simulate the model (and the code is debugged)\n",
    "\n",
    "- study the implications of theoretical assumptions of various models and theories  \n",
    "- run numerical simulations of optimal decisions and policies (for particular values or ranges of values of model parameters)  \n",
    "\n",
    "\n",
    "But the **ultimate goal is to match the model to the actually observed data**, and:\n",
    "\n",
    "- quantify of the effects of various parts of the theoretical setup  \n",
    "- perform **counterfactual experiments** simulating the behavior of the decision maker in hypothetical policy regimes  \n",
    "- support or falsify theoretical results by examining their fit to the observed data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Structural estimation\n",
    "\n",
    "1. Given the theoretical model of behavior, ..  \n",
    "1. and its numerical implementation, ..  \n",
    "1. formulate a statistical procedure (estimator) to find parameter values such that the model describes the observed data in the best possible way, and  \n",
    "1. assess the variability of these values (compute standard errors of the estimates)  \n",
    "\n",
    "\n",
    "*Structural estimation is the field of econometrics centered around methodological development and applications of the described approach*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Structural vs. reduced form econometrics\n",
    "\n",
    "Long standing opposition, although the boundary is blurred\n",
    "\n",
    "- Structural: theoretical model + direct estimation of parameters from the observed data  \n",
    "- Reduced form: econometric model with standard assumptions + data analysis  \n",
    "\n",
    "\n",
    "The fields are becoming closer: RCTs, controlled experiments, causal econometric methods (IV, regression discontinuity), applications in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sources of identification of (structural) parameters of the model\n",
    "\n",
    "1. the variation of the observed data  \n",
    "1. theoretical structure of the model (assumptions on **causality** such as *exclusion restrictions*, *functional forms* and *distributional assumptions*)  \n",
    "\n",
    "\n",
    "- Structural: low level assumptions informed by the economic theory  \n",
    "- Reduced form: higher level assumptions informed by econometric models  \n",
    "\n",
    "\n",
    "Foundation on economic theory $ \\Rightarrow $ counterfactual simulations using structurally estimated model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Counterfactual simulations\n",
    "\n",
    "1. Estimate the model using observed data  \n",
    "1. Simulate data under status quo  \n",
    "1. Change the policy environment  \n",
    "1. Simulate data under alternative regime  \n",
    "1. Compare to reveal the effects of the policy  \n",
    "1. Perform *uncertainly quantification* to assess the variability of the results  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Theoretical grounds for counterfactual simulations\n",
    "\n",
    "- uncovering deep behavioral parameters $ \\rightarrow $  \n",
    "- possible to assume they are not changing in policy change (policy invariant) $ \\rightarrow $  \n",
    "- possible to simulate decision making in a different policy environment  \n",
    "\n",
    "\n",
    "*Pure data analysis is incapable of counterfactual simulations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Estimation vs. calibration\n",
    "\n",
    "What is the difference?  Sometimes the terms are used interchangeably\n",
    "\n",
    "- **Standard errors of estimates** (measure of variability of the estimation results)  \n",
    "- **Study of identification** (to make sure that other parameter values can not match the data equally well)  \n",
    "\n",
    "\n",
    "Calibration exercises often skip these steps, even if employing algorithmic search of best parameters to fit the model to the data.\n",
    "\n",
    "Applications of estimation sometimes estimate only a subset of parameters, treating other as fixed, similar to calibration with parameter values from the literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Workflow of structural estimation\n",
    "\n",
    "1. Theoretical model development (what is of interest?)  \n",
    "1. Practical specification/implementation issues  \n",
    "1. Solving the model (method + implementation in the code)  \n",
    "1. *Understanding how the model works*  \n",
    "1. Estimation: running the statistical procedure  \n",
    "1. Validation (assessing out-of-sample performance)  \n",
    "1. Policy experiments, counterfactual simulations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example: Stochastic consumption-savings model\n",
    "\n",
    "1. Theoretical model: see **video 35, 39**  \n",
    "1. Implementation: see **video 40, 42**  \n",
    "1. Solving the model: see **video 37**  \n",
    "1. **Understanding how the model works**  \n",
    "1. **Estimation**  \n",
    "1. Validation: *talk to me if interested*  \n",
    "1. Policy experiments: *talk to me if interested*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#COPY from video 42\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import interpolate\n",
    "from scipy.stats import lognorm\n",
    "from scipy.optimize import minimize_scalar, brentq\n",
    "\n",
    "class deaton():\n",
    "    '''Implementation of the stochastic Deaton consumption-savings problem with random income.'''\n",
    "\n",
    "    def __init__(self, Mbar=10,\n",
    "                 ngrid=50, nchgrid=100, nquad=10,\n",
    "                 interpolation='linear', bellman_type='discretized',\n",
    "                 maxiter_internal=250, tol_internal=1e-10,\n",
    "                 beta=.9, R=1.05, sigma=1.):\n",
    "        '''Object creator for the stochastic consumption-savings model'''\n",
    "        self.beta = beta        # Discount factor\n",
    "        self.R = R              # Gross interest\n",
    "        self.sigma = sigma      # Param in log-normal income distribution\n",
    "        self.Mbar = Mbar        # Upper bound on wealth\n",
    "        self.ngrid = ngrid      # Number of grid points in the state space\n",
    "        self.nchgrid = nchgrid  # Number of grid points in the decision space\n",
    "        self.nquad = nquad      # Number of quadrature points\n",
    "        self.interpolation = interpolation  # type of interpolation, see below\n",
    "        self.bellman_type = bellman_type  # type of Bellman operator\n",
    "        self.maxiter_internal = maxiter_internal  # maxiter for continuous Bellman operator\n",
    "        self.tol_internal = tol_internal  # tolerance for continuous Bellman operator\n",
    "        # state and choice space grids, as well as quadrature points and weights are set with setter functions below\n",
    "\n",
    "    def __repr__(self):\n",
    "        '''String representation for the model'''\n",
    "        return 'Deaton model with beta={:1.3f}, sigma={:1.3f}, gross return={:1.3f}\\nGrids: state {} points up to {:1.1f}, choice {} points, quadrature {} points\\nInterpolation: {}\\nThe model is {}solved.'\\\n",
    "               .format(self.beta,self.sigma,self.R,self.ngrid,self.Mbar,self.nchgrid,self.nquad,self.interpolation,'' if hasattr(self,'solution') else 'not ')\n",
    "\n",
    "    @property\n",
    "    def ngrid(self):\n",
    "        '''Property getter for the ngrid parameter'''\n",
    "        return self.__ngrid\n",
    "\n",
    "    @ngrid.setter\n",
    "    def ngrid(self,ngrid):\n",
    "        '''Property setter for the ngrid parameter'''\n",
    "        self.__ngrid = ngrid\n",
    "        epsilon = np.finfo(float).eps # smallest positive float number difference\n",
    "        self.grid = np.linspace(epsilon,self.Mbar,ngrid) # grid for state space\n",
    "\n",
    "    @property\n",
    "    def nchgrid(self):\n",
    "        '''Property getter for the nchgrid parameter'''\n",
    "        return self.__nchgrid\n",
    "\n",
    "    @nchgrid.setter\n",
    "    def nchgrid(self,nchgrid):\n",
    "        '''Property setter for the nchgrid parameter'''\n",
    "        self.__nchgrid = nchgrid\n",
    "        epsilon = np.finfo(float).eps # smallest positive float number difference\n",
    "        self.chgrid = np.linspace(epsilon,self.Mbar,nchgrid) # grid for state space\n",
    "\n",
    "    @property\n",
    "    def bellman_type(self):\n",
    "        '''Property getter for the bellman_type parameter'''\n",
    "        return self.__bellman_type\n",
    "\n",
    "    @bellman_type.setter\n",
    "    def bellman_type(self,value):\n",
    "        '''Property setter for the bellman_type parameter'''\n",
    "        self.__bellman_type = value\n",
    "        if value == 'discretized':\n",
    "            self.bellman = self.bellman_discretized\n",
    "        elif value == 'continuous':\n",
    "            self.bellman = self.bellman_continuous\n",
    "        else:\n",
    "            raise RuntimeError('Unknown Bellman type parameter')\n",
    "\n",
    "    @property\n",
    "    def sigma(self):\n",
    "        '''Property getter for the sigma parameter'''\n",
    "        return self.__sigma\n",
    "\n",
    "    @sigma.setter\n",
    "    def sigma(self,sigma):\n",
    "        '''Property setter for the sigma parameter'''\n",
    "        self.__sigma = sigma\n",
    "        self.__quadrature_setup()  # update quadrature points and weights\n",
    "\n",
    "    @property\n",
    "    def nquad(self):\n",
    "        '''Property getter for the number of quadrature points'''\n",
    "        return self.__nquad\n",
    "\n",
    "    @nquad.setter\n",
    "    def nquad(self,nquad):\n",
    "        '''Property setter for the number of quadrature points'''\n",
    "        self.__nquad = nquad\n",
    "        self.__quadrature_setup()  # update quadrature points and weights\n",
    "\n",
    "    def __quadrature_setup(self):\n",
    "        '''Internal function to set up quadrature points and weights,\n",
    "        depends on sigma and nquad, therefore called from the property setters\n",
    "        '''\n",
    "        try:\n",
    "            # quadrature points and weights for log-normal distribution\n",
    "            self.quadp,self.quadw = np.polynomial.legendre.leggauss(self.__nquad) # Gauss-Legendre for [-1,1]\n",
    "            self.quadp = (self.quadp+1)/2 # rescale to [0,1]\n",
    "            self.quadp = lognorm.ppf(self.quadp,self.__sigma) # inverse cdf\n",
    "            self.quadw /= 2 # rescale weights as well\n",
    "        except(AttributeError):\n",
    "            # when __nquad or __sigma are not yet set\n",
    "            pass\n",
    "\n",
    "    def utility(self,c):\n",
    "        '''Utility function'''\n",
    "        return np.log(c)\n",
    "\n",
    "    def marginal_utility(self,c):\n",
    "        '''Marginal utility function'''\n",
    "        return 1/c\n",
    "\n",
    "    def inverse_marginal_utility(self,u):\n",
    "        '''Marginal utility function'''\n",
    "        return 1/u\n",
    "\n",
    "    def next_period_wealth(self,M,c,y):\n",
    "        '''Next period budget'''\n",
    "        if self.nquad>1:\n",
    "            return self.R*(M-c) + y  # next period wealth\n",
    "        else:\n",
    "            return self.R*(M-c) + np.zeros(shape=y.shape) # next period wealth without income\n",
    "\n",
    "    def interp_func(self,x,f):\n",
    "        '''Returns the interpolation function for given data'''\n",
    "        if self.interpolation=='linear':\n",
    "            return interpolate.interp1d(x,f,kind='slinear',fill_value=\"extrapolate\")\n",
    "        elif self.interpolation=='quadratic':\n",
    "            return interpolate.interp1d(x,f,kind='quadratic',fill_value=\"extrapolate\")\n",
    "        elif self.interpolation=='cubic':\n",
    "            return interpolate.interp1d(x,f,kind='cubic',fill_value=\"extrapolate\")\n",
    "        elif self.interpolation=='polynomial':\n",
    "            p = np.polynomial.polynomial.polyfit(x,f,self.ngrid_state-1)\n",
    "            return lambda x: np.polynomial.polynomial.polyval(x,p)\n",
    "        else:\n",
    "            print('Unknown interpolation type')\n",
    "            return None\n",
    "\n",
    "    def bellman_discretized(self,V0):\n",
    "        '''Bellman operator with discretized choice,\n",
    "           V0 is 1-dim vector of values on the state grid\n",
    "        '''\n",
    "        c = self.chgrid[:,np.newaxis,np.newaxis]   # axis 0: choices\n",
    "        M = self.grid[np.newaxis,:,np.newaxis]     # axis 1: states\n",
    "        y = self.quadp[np.newaxis,np.newaxis,:]    # axis 2: quadrature points\n",
    "        c = c.repeat(self.ngrid,axis=1).repeat(self.nquad,axis=2)  # 3-dim array of choices\n",
    "        c *= M/self.Mbar                           # scale values of choices to ensure c<=M\n",
    "        M1 = self.next_period_wealth(M,c,y)        # 3-dim array with quad point in last dimension\n",
    "        inter = self.interp_func(self.grid,V0)            # interpolating function for next period value function\n",
    "        V1 = inter(M1)                                    # value function at next period wealth, 3-dim array\n",
    "        EV = np.dot(V1,self.quadw)                        # expected value function, 2-dim matrix\n",
    "        MX = self.utility(c[:,:,0]) + self.beta*EV        # maximand of Bellman equation, 2-dim matrix\n",
    "        MX[c[:,:,0]>M[:,:,0]] = -np.inf                   # infeasible choices should have -inf (just in case)\n",
    "        V1 = np.amax(MX,axis=0,keepdims=False)            # optimal choice as maximum in every column, 1-dim vector\n",
    "        c1 = c[np.argmax(MX,axis=0),range(self.ngrid),0]  # choose the max attaining levels of c\n",
    "        return V1, c1\n",
    "\n",
    "    def bellman_continuous(self,V0):\n",
    "        '''Bellman operator with continuous choice,\n",
    "           V0 is 1-dim vector of values on the state grid\n",
    "        '''\n",
    "        def maximand(c,M,interf):\n",
    "            '''Maximand of the Bellman equation'''\n",
    "            M1 = self.next_period_wealth(M,c,self.quadp)  # vector of next period wealth\n",
    "            V1 = interf(M1)                               # value function at next period wealth\n",
    "            EV = np.dot(V1,self.quadw)                    # expected value function, scalar\n",
    "            MX = self.utility(c) + self.beta*EV           # maximand of Bellman equation, scalar\n",
    "            return -MX # negative because of minimization\n",
    "\n",
    "        def findC(M,interf):\n",
    "            '''Solves for optimal consumption for given wealth M'''\n",
    "            if M<=self.grid[0]:\n",
    "                return M  # return M if it is too close to zero\n",
    "            opt = {'maxiter':self.maxiter_internal, 'xatol':self.tol_internal}\n",
    "            res = minimize_scalar(maximand,args=(M,interf),method='Bounded',bounds=[self.grid[0],M],options=opt)\n",
    "            if res.success:\n",
    "                return res.x # if converged successfully\n",
    "            else:\n",
    "                raise RuntimeError('Bellman continuous failed to find optimal consumption')\n",
    "\n",
    "        interfunc = self.interp_func(self.grid,V0)  # interpolation function for V0\n",
    "        V1=np.empty(self.ngrid,dtype='float')    # allocate space for the policy function\n",
    "        c1=np.empty(self.ngrid,dtype='float')    # allocate space for the value function\n",
    "        for i,M in enumerate(self.grid):         # loop over state space\n",
    "            c1[i] = findC(M,interfunc)           # find optimal consumption\n",
    "            V1[i] = -maximand(c1[i],M,interfunc) # value function, don't forget the negation!\n",
    "        return V1, c1\n",
    "\n",
    "    def euler_residual(self,c,M,policy):\n",
    "        '''Computes the Euler residuals for a given points (M,c), and\n",
    "           given policy function that enters into the RHS\n",
    "           Argument policy is interpolation function for the policy\n",
    "        '''\n",
    "        # assume that c and M are either scalars or 1-dim arrays of the same size\n",
    "        if isinstance(c,np.ndarray):\n",
    "            c0,M0 = c[:,np.newaxis],M[:,np.newaxis]  # axis 0: choices and states\n",
    "            y = self.quadp[np.newaxis,:]             # axis 1: quadrature points\n",
    "        else:\n",
    "            c0,M0 = c,M\n",
    "            y = self.quadp                           # 1-dim array of quadrature points\n",
    "        M1 = self.next_period_wealth(M0,c0,y)        # 1-dim or 2-dim array with quad point in last dimension\n",
    "        c1 = np.maximum(policy(M1),self.grid[0])     # value function at next period wealth, 3-dim array\n",
    "        mu = self.marginal_utility(c1)               # marginal utility in the RHS\n",
    "        RHS = self.beta*self.R*np.dot(mu,self.quadw) # RHS of Euler equation\n",
    "        LHS = self.marginal_utility(c)\n",
    "        return LHS-RHS\n",
    "\n",
    "    def solve_egm (self,maxiter=500,tol=1e-4,callback=None):\n",
    "        '''Solves the model using EGM (successive approximations of efficient Coleman-Reffet operator)\n",
    "           Callback function is invoked at each iteration with keyword arguments.\n",
    "        '''\n",
    "        A = np.linspace(0,self.Mbar,self.ngrid)  # grid on savings\n",
    "        interp = lambda x,f: interpolate.interp1d(x,f,kind='slinear',fill_value=\"extrapolate\") # linear interpolation\n",
    "        c0 = interp([0,self.Mbar],[0,self.Mbar]) # initial policy function\n",
    "        V0 = self.utility(self.grid)\n",
    "        for iter in range(maxiter):\n",
    "            # EGM step\n",
    "            M1 = self.next_period_wealth(A[:,np.newaxis],0,self.quadp[np.newaxis,:]) # matrix with A in axis=0, y/quadpoints in axis=1\n",
    "            c1 = np.maximum(c0(M1),self.grid[0])         # value function at next period wealth, 3-dim array\n",
    "            mu = self.marginal_utility(c1)               # marginal utility in the RHS\n",
    "            RHS = self.beta*self.R*np.dot(mu,self.quadw) # RHS of Euler equation\n",
    "            c = np.empty(self.ngrid+1,dtype=float)\n",
    "            M = np.empty(self.ngrid+1,dtype=float)\n",
    "            c[0] = M[0] = 0.\n",
    "            c[1:] = self.inverse_marginal_utility(RHS)    # current period consumption (vector)\n",
    "            M[1:] = c[1:] + A                             # vector of endogenous points on M\n",
    "            c1 = interp(M,c)                              # updated policy function\n",
    "            c1grid = c1(self.grid)                        # vector representation of policy function\n",
    "            # matrix of next period wealth, states in axis=0, quadpoint in axis=1\n",
    "            M1 = self.next_period_wealth(self.grid[:,np.newaxis],c1grid[:,np.newaxis],self.quadp[np.newaxis,:])\n",
    "            interfunc = self.interp_func(self.grid,V0)    # interpolcation for the value function\n",
    "            V  = interfunc(M1)                            # value function at next period wealth\n",
    "            EV = np.dot(V,self.quadw)                     # expected value function, vector\n",
    "            V1 = self.utility(c1grid) + self.beta*EV      # maximand of Bellman equation, column-vector\n",
    "            err = np.amax(np.abs(c1grid-c0(self.grid)))\n",
    "            if callback: callback(iter=iter,model=self,value=V1,policy=c1grid,err=err) # callback for making plots\n",
    "            if err < tol:\n",
    "                break  # converged!\n",
    "            c0,V0 = c1,V1  # prepare for the next iteration\n",
    "        else:  # when iter went up to maxiter\n",
    "            raise RuntimeError('No convergence: maximum number of iterations achieved!')\n",
    "        self.solution = {'value':V1,'policy':c1grid,'solver':'egm'}  # save the model solution to the object\n",
    "        return V1,c1grid\n",
    "\n",
    "\n",
    "    def solve_timeiter (self,maxiter=500,tol=1e-4,callback=None):\n",
    "        '''Solves the model using time iterations (successive approximations of Coleman-Reffet operator)\n",
    "           Callback function is invoked at each iteration with keyword arguments.\n",
    "        '''\n",
    "        c0 = self.grid # on first iteration assume consuming everything\n",
    "        V0 = self.utility(self.grid)\n",
    "        for iter in range(maxiter):\n",
    "            c1 = np.empty(self.ngrid,dtype=float)  # allocate space for policy and value functions\n",
    "            V1 = np.empty(self.ngrid,dtype=float)\n",
    "            c0inter = self.interp_func(self.grid,c0)  # interpolation function for policy c0\n",
    "            for i,M in enumerate(self.grid):\n",
    "                if M<=self.grid[0] or self.euler_residual(c=M,M=M,policy=c0inter)>0:\n",
    "                    c1[i] = M  # corner solution\n",
    "                else:\n",
    "                    c1[i] = brentq(self.euler_residual,args=(M,c0inter),a=self.grid[0],b=M,\n",
    "                                  xtol=self.tol_internal,maxiter=self.maxiter_internal,\n",
    "                                  full_output=False,disp=True)  # optimal consumption level for given M\n",
    "                # calculation of the value function for given M and found optimal consumption c1[i]\n",
    "                interfunc = self.interp_func(self.grid,V0)\n",
    "                M1 = self.next_period_wealth(M,c1[i],self.quadp)  # vector of next period wealth\n",
    "                V  = interfunc(M1)                                # value function at next period wealth\n",
    "                EV = np.dot(V,self.quadw)                        # expected value function, scalar\n",
    "                V1[i] = self.utility(c1[i]) + self.beta*EV        # maximand of Bellman equation, scalar\n",
    "            err = np.amax(np.abs(c1-c0))\n",
    "            if callback: callback(iter=iter,model=self,value=V1,policy=c1,err=err) # callback for making plots\n",
    "            if err < tol:\n",
    "                break  # converged!\n",
    "            c0,V0 = c1,V1  # prepare for the next iteration\n",
    "        else:  # when iter went up to maxiter\n",
    "            raise RuntimeError('No convergence: maximum number of iterations achieved!')\n",
    "        self.solution = {'value':V1,'policy':c1,'solver':'time iterations'}  # save the model solution to the object\n",
    "        return V1,c1\n",
    "\n",
    "    def solve_vfi (self,maxiter=500,tol=1e-4,callback=None):\n",
    "        '''Solves the model using value function iterations (successive approximations of Bellman operator)\n",
    "           Callback function is invoked at each iteration with keyword arguments.\n",
    "        '''\n",
    "        V0 = self.utility(self.grid) # on first iteration assume consuming everything\n",
    "        for iter in range(maxiter):\n",
    "            V1,c1 = self.bellman(V0)\n",
    "            err = np.amax(np.abs(V1-V0))\n",
    "            if callback: callback(iter=iter,model=self,value=V1,policy=c1,err=err) # callback for making plots\n",
    "            if err < tol:\n",
    "                break  # converged!\n",
    "            V0 = V1  # prepare for the next iteration\n",
    "        else:  # when iter went up to maxiter\n",
    "            raise RuntimeError('No convergence: maximum number of iterations achieved!')\n",
    "        self.solution = {'value':V1,'policy':c1,'solver':'VFI with {} Bellman'.format(self.bellman_type)}  # save the model solution to the object\n",
    "        return V1,c1\n",
    "\n",
    "    def solve_plot(self,solver,**kvarg):\n",
    "        '''Illustrate solution\n",
    "           Inputs: solver (string), and any inputs to the solver\n",
    "        '''\n",
    "        if solver=='vfi':\n",
    "            solver_func = self.solve_vfi\n",
    "        elif solver=='timeiter':\n",
    "            solver_func = self.solve_timeiter\n",
    "        elif solver=='egm':\n",
    "            solver_func = self.solve_egm\n",
    "        else:\n",
    "            raise ValueError('Unknown solver label')\n",
    "        fig1, (ax1,ax2) = plt.subplots(1,2,figsize=(14,8))\n",
    "        ax1.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax2.grid(b=True, which='both', color='0.65', linestyle='-')\n",
    "        ax1.set_title('Value function convergence with %s'%solver)\n",
    "        ax2.set_title('Policy function convergence with %s'%solver)\n",
    "        ax1.set_xlabel('Wealth, M')\n",
    "        ax2.set_xlabel('Wealth, M')\n",
    "        ax1.set_ylabel('Value function')\n",
    "        ax2.set_ylabel('Policy function')\n",
    "        def callback(**kwargs):\n",
    "            print('|',end='')\n",
    "            grid = kwargs['model'].grid\n",
    "            v = kwargs['value']\n",
    "            c = kwargs['policy']\n",
    "            ax1.plot(grid[1:],v[1:],color='k',alpha=0.25)\n",
    "            ax2.plot(grid,c,color='k',alpha=0.25)\n",
    "        V,c = solver_func(callback=callback,**kvarg)\n",
    "        # add solutions\n",
    "        ax1.plot(self.grid[1:],V[1:],color='r',linewidth=2.5)\n",
    "        ax2.plot(self.grid,c,color='r',linewidth=2.5)\n",
    "        plt.show()\n",
    "        return V,c\n",
    "\n",
    "    def accuracy(self,dense_grid_factor=10,verbose=False):\n",
    "        '''Compute the average squared Euler residuals for the saved solution'''\n",
    "        assert hasattr(self,'solution'), 'Need to solve the model to compute the accuracy measure!'\n",
    "        grid = np.linspace(self.grid[0],self.Mbar,self.ngrid*dense_grid_factor) # dense grid for state space\n",
    "        inter = self.interp_func(self.grid,self.solution['policy'])  # interpolation function for policy function\n",
    "        c = inter(grid)  # consumption on the dense grid\n",
    "        er = self.euler_residual(c=c,M=grid,policy=inter)\n",
    "        er = er[np.logical_not(np.isclose(c,grid,atol=1e-10))]  # disregard corner solutions\n",
    "        acc = np.mean(er**2)\n",
    "        if verbose:\n",
    "            print('Average squared Euler residuals ({}) using {} points is {}'.format(\n",
    "                self.solution['solver'],self.ngrid*dense_grid_factor,acc))\n",
    "        else:\n",
    "            return acc\n",
    "\n",
    "    def simulator(self,init_wealth=1,T=10,seed=None,plot=True):\n",
    "        '''Simulation of the model for given number of periods from given initial conditions'''\n",
    "        assert hasattr(self,'solution'), 'Need to solve the model before simulating!'\n",
    "        if seed!=None:\n",
    "            np.random.seed(seed)  # fix the seed if needed\n",
    "        init_wealth = np.asarray(init_wealth).ravel()  # flat np array of initial wealth\n",
    "        N = init_wealth.size  # number of trajectories to simulate\n",
    "        sim = {'M':np.empty((N,T+1)),'c':np.empty((N,T+1))}\n",
    "        sim['M'][:,0] = init_wealth  # initial wealth in the first column\n",
    "        inter = self.interp_func(self.grid,self.solution['policy'])  # interpolation function for policy function\n",
    "        for t in range(T+1):\n",
    "            sim['c'][:,t] = inter(sim['M'][:,t])  # optimal consumption in period t\n",
    "            if t<T:\n",
    "                y = lognorm.rvs(self.sigma,size=N) # draw random income\n",
    "                sim['M'][:,t+1] = self.next_period_wealth(sim['M'][:,t],sim['c'][:,t],y) # next period wealth\n",
    "        if plot:\n",
    "            fig, (ax1,ax2) = plt.subplots(2,1,figsize=(12,6))\n",
    "            ax1.set_title('Simulated wealth and consumption trajectories')\n",
    "            ax1.set_ylabel('Wealth')\n",
    "            ax2.set_ylabel('Consumption')\n",
    "            ax2.set_xlabel('Time period in the simulation')\n",
    "            for ax in (ax1,ax2):\n",
    "                ax.grid(b=True, which='both', color='0.95', linestyle='-')\n",
    "            for i in range(N):\n",
    "                ax1.plot(sim['M'][i,:],alpha=0.75)\n",
    "                ax2.plot(sim['c'][i,:],alpha=0.75)\n",
    "            plt.show()\n",
    "        return sim # return simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Understanding how the model works — simple algorithm\n",
    "\n",
    "1. Solve the model for a set of parameter values  \n",
    "1. Simulated data from the model  \n",
    "1. Does it make (economic) sense?  \n",
    "1. Repeat (many-many times)  \n",
    "\n",
    "\n",
    "- may take *a lot of time* to convince yourself that the code does not have bugs  \n",
    "- unexpected/surprising results still appear?  Making research progress!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# deterministic model with βR=1 and y=1\n",
    "m = deaton(beta=0.9,R=1/0.9,ngrid=100,nchgrid=250,sigma=1e-10,nquad=2)\n",
    "m.solve_egm(tol=1e-10)\n",
    "init_wealth, T = [1.75,2.25], 50\n",
    "m.simulator(init_wealth=init_wealth,T=T,seed=2020)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# deterministic model with R=1 and y=1\n",
    "m = deaton(beta=0.9,R=1.0,ngrid=100,nchgrid=250,sigma=1e-10,nquad=2)\n",
    "m.solve_egm(tol=1e-10)\n",
    "init_wealth, T = [1.75,2.25], 50\n",
    "m.simulator(init_wealth=init_wealth,T=T,seed=2020)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# two stochastic models with different income variance\n",
    "m1 = deaton(beta=0.9,R=1.05,ngrid=100,nchgrid=250,sigma=0.5)\n",
    "m2 = deaton(beta=0.9,R=1.05,ngrid=100,nchgrid=250,sigma=0.85)\n",
    "m1.solve_egm(tol=1e-10)\n",
    "m2.solve_egm(tol=1e-10)\n",
    "init_wealth, T = [1.75,2.25], 50\n",
    "m1.simulator(init_wealth=init_wealth,T=T,seed=2020)\n",
    "m2.simulator(init_wealth=init_wealth,T=T,seed=2020)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# two stochastic models with different dicount coefficients\n",
    "m1 = deaton(beta=0.85,R=1.05,ngrid=100,nchgrid=250,sigma=1.5)\n",
    "m2 = deaton(beta=0.95,R=1.05,ngrid=100,nchgrid=250,sigma=1.5)\n",
    "m1.solve_egm(tol=1e-10)\n",
    "m2.solve_egm(tol=1e-10)\n",
    "init_wealth, T = [1.75,2.25], 50\n",
    "m1.simulator(init_wealth=init_wealth,T=T,seed=2020)\n",
    "m2.simulator(init_wealth=init_wealth,T=T,seed=2020)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Method of simulated moments\n",
    "\n",
    "- we have seen how changing parameters is reflected in changes in the simulated wealth and consumption profiles  \n",
    "- imagine we have data on observed consumption or wealth profiles for a sample of people, or even some aggregate data on consumption or wealth  \n",
    "- then we can find parameters of the model that would induce the simulated data to reflect the observed profiles, or some descriptive statistics (*moments*) of these profiles  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Simulated moments\n",
    "\n",
    "The idea of *directly* matching the moments from the model to the observed ones leads to the method of moments estimator\n",
    "\n",
    "- Method of moments: # of parameters = # of moments to match, system of equations  \n",
    "- Generalized method of moments (GMM): # of parameters < # of moments, minimize the distance between the data moments and theoretical moments  \n",
    "- Method of simulated moments (MSM): using simulations to compute the theoretical moments  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Definition of MSM estimator\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{MSM}(W) = \\arg\\min_{\\theta \\in \\Theta} \\, e(\\tilde{x},x|\\theta) \\, W e(\\tilde{x},x|\\theta)^{T}\n",
    "$$\n",
    "\n",
    "- $ \\theta \\in \\Theta $ is parameter space  \n",
    "- $ e(\\tilde{x},x|\\theta) $ is the row-vector of $ K $ moment conditions  \n",
    "- $ W $ is the $ K \\times K $ weighting matrix  \n",
    "- $ x $ and $ \\tilde{x} $ is observed and simulated data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Moments and moment conditions\n",
    "\n",
    "$$\n",
    "e(\\tilde{x},x|\\theta) = \\big(e^1(\\tilde{x},x|\\theta),\\dots,e^K(\\tilde{x},x|\\theta) \\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "e^k(\\tilde{x},x|\\theta) = m^k(x) - m^k(\\tilde{x}|\\theta)\n",
    "$$\n",
    "\n",
    "- $ m^k(\\cdot) $ is the $ k $-th moment generating function  \n",
    "- $ m^k(x) $ are empirical moments (computed from the observed data)  \n",
    "- $ m^k(\\tilde{x}|\\theta) $ are the simulated moments (computed from the simulated data using parameter values $ \\theta $)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Theory of MSM\n",
    "\n",
    "📖 McFadden 1989 *Econometrica* “A method of simulated moments for estimation of discrete response models without numerical integration”\n",
    "\n",
    "📖 Pakes and Pollard 1989 *Econometrica* “Simulation and the Asymptotics of Optimization Estimators”\n",
    "\n",
    "📖 Lee and Ingram 1991 *Journal of Econometrics* “Simulation estimation of time-series models”\n",
    "\n",
    "📖 Duffie and Singleton 1993 *Econometrica* “Simulated moments estimation of Markov models of asset”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Statistical properties of MSM estimator\n",
    "\n",
    "1. $ \\hat{\\theta}_{MSM}(W) $ is consistent with any weighting matrix $ W $  \n",
    "1. $ \\hat{\\theta}_{MSM}(W) $ is asymptotically normal $ \\hat{\\theta}_{MSM}(W) \\sim N(0,\\Sigma) $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Variance-covariance matrix of the estimate\n",
    "\n",
    "$$\n",
    "\\hat{\\Sigma} = (1+\\tfrac{1}{\\tau})(D^{T} W D)^{-1} D^{T}W \\hat{S} W D (D^{T}WD)^{-1}\n",
    "$$\n",
    "\n",
    "- $ W $ is weighting matrix  \n",
    "- $ D = \\partial e(\\tilde{x},x|\\theta) \\big/ \\partial \\theta $ is the Jacobian matrix of moment conditions, computed at consistent estimate $ \\theta $  \n",
    "- $ S $ is variance-covariance matrix of the moment conditions $ e(\\tilde{x},x|\\theta) $  \n",
    "- $ \\hat{S} $ is estimate of $ S $, usually computed using simulations as well  \n",
    "- $ \\tau $ is the ratio of the simulated to empirical samples sizes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Optimal weighting matrix\n",
    "\n",
    "- the asymptotic variance of the estimates is minimized when the weighting matrix is given by the inverse of the variance-covariance matrix of the moment conditions (at true value of the parameter)  \n",
    "- the estimate of the variance-covariance matrix of the MSM estimate then becomes  \n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\Sigma} = (1+\\tfrac{1}{\\tau})(D^{T} W D)^{-1}\n",
    "$$\n",
    "\n",
    "- weighting matrix can be estimated using the simulated analog  \n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{W}^\\star = \\big(\\hat{S}\\big)^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Weighting matrix in practice\n",
    "\n",
    "- identity = in the first step of multi-step MSM estimations  \n",
    "- diagonal weighting matrix, ignoring the covariances  \n",
    "- manually chosen weights, i.e. to bring all the moments to the same scale  \n",
    "- using sample variance to downgrade poorly measured empirical moments  \n",
    "- estimated from the moment conditions based on first step consistent estimate  \n",
    "- iteratively updated weighting using multi-step estimating procedure  \n",
    "- Newey-West robust estimate of weighting matrix  \n",
    "- additional model-specific adjustments  \n",
    "\n",
    "\n",
    "*Many ways to skin a cat*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Choice of moments\n",
    "\n",
    "- crucial part for MSM estimation = being able to minimize the MSM criterion  \n",
    "- more art than science  \n",
    "- understanding how the model works = understanding what variation is induced in simulated data when parameters change  \n",
    "- selected for estimation $ K $ moments should adequately represent this variation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Practical advantages of MSM\n",
    "\n",
    "- not data hungry (may match aggregated moments)  \n",
    "- allows to combine different sources of data  \n",
    "- does not rely on the distributional assumptions as much as MLE  \n",
    "- but lacks in efficiency, so standard errors are larger than MLE  \n",
    "- weighting matrix is often simplified in practice due to small sample bias  \n",
    "\n",
    "\n",
    "Widely used method in applied research!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# For this exercise the DATA will be given by\n",
    "model = deaton(beta=0.92,Mbar=50,ngrid=100)\n",
    "model.solve_egm()\n",
    "np.random.seed(14) # fix seed for initial draws\n",
    "init_wealth = np.exp(np.random.randn(50)) # draw initial wealth\n",
    "np.random.seed(15) # fix seed for simulations\n",
    "data = model.simulator(init_wealth=init_wealth,T=60)\n",
    "data_wealth = data['M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def moments_function(data,tail=10):\n",
    "    '''Computes two moments: mean and std dev from\n",
    "       the tail of the given time series (from last axis)\n",
    "       Returns two vectors with moments computed at individual level\n",
    "    '''\n",
    "    d = data.ndim-1  # last dimension\n",
    "    mean = np.mean(data[:,-tail:],axis=d)\n",
    "    std = np.std(data[:,-tail:],axis=d)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Data moments\n",
    "print('Number of observed individuals: ',data_wealth.shape[0],sep=' ')\n",
    "print('Number of observed time periods:',data_wealth.shape[1],sep=' ')\n",
    "data_moment1, data_moment2 = moments_function(data_wealth)  # data moments on individual level (of observed sample)\n",
    "data_moment1_mean, data_moment1_std = np.mean(data_moment1), np.std(data_moment1)  # descriptive stats for empirical moments\n",
    "data_moment2_mean, data_moment2_std = np.mean(data_moment2), np.std(data_moment2)\n",
    "print(f'Moment 1 (mean wealth), mean and std.dev. over data sample  : {data_moment1_mean:.5f} ({data_moment1_std:.5f})')\n",
    "print(f'Moment 2 (std of wealth), mean and std.dev. over data sample: {data_moment2_mean:.5f} ({data_moment2_std:.5f})')\n",
    "data_moments_vec = np.array([data_moment1_mean,data_moment2_mean])  # vector of aggregated moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# MSM estimation exercise\n",
    "model = deaton(beta=0.95,Mbar=50,ngrid=100)  # init the model\n",
    "np.random.seed(214)                          # fix for initial wealth\n",
    "init_wealth = np.exp(np.random.randn(250))   # draw initial wealth\n",
    "\n",
    "def moment_conditions(theta,data_moments,seed=215):\n",
    "    '''Moment conditions for MSM estimator,\n",
    "       Inputs: parameter vector + vector of aggregated data moments\n",
    "       Computed at the individual level.\n",
    "       Random number generator seed fixed by default.\n",
    "    '''\n",
    "    model.beta = theta\n",
    "    np.random.seed(seed) # must be fixed between calls!\n",
    "    model.solve_egm(maxiter=1000)\n",
    "    simdata = model.simulator(init_wealth=init_wealth,T=60,plot=False)\n",
    "    # compute simulated moments\n",
    "    sim_moment1, sim_moment2 = moments_function(simdata['M'])\n",
    "    return sim_moment1 - data_moments[0], sim_moment2 - data_moments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.misc import derivative\n",
    "\n",
    "def run_MSM(data_moments = data_moments_vec,                 # vector of data moments\n",
    "            moment_conditions_function = moment_conditions,  # moment conditions generator\n",
    "            W = None,                                        # weighting matrix\n",
    "            bracket = [.85,.95],                             # approximate limits for the parameters\n",
    "            plot = True):\n",
    "    '''Run the MSM estimation\n",
    "       Returns estimates and std.err. of estimates\n",
    "    '''\n",
    "\n",
    "    def mean_conditions(theta):\n",
    "        '''Means of the moment conditions returned as a vector'''\n",
    "        moms = moment_conditions_function(theta,data_moments)  # return a tuple\n",
    "        moms = np.array(moms)  # convert to array, moments in axis=0, indiv in axis=1\n",
    "        return np.mean(moms,axis=1)  # vector of means of moment conditions\n",
    "\n",
    "    def criterion(theta,W):\n",
    "        '''Criterion function for MSM estimator'''\n",
    "        err = mean_conditions(theta)\n",
    "        return err @ W @ err.T\n",
    "\n",
    "    if W is None:\n",
    "        # default weighting matrix = identity\n",
    "        check = moment_conditions_function(1.0,data_moments)  # check how many moments\n",
    "        W = np.eye(len(check))\n",
    "\n",
    "    # minimize the criterion function\n",
    "    res = minimize_scalar(criterion,method='Brent',args=(W),bracket=bracket,tol=1e-8)\n",
    "    if not res.success:\n",
    "        raise RuntimeError('Bellman continuous failed to find optimal consumption')\n",
    "    theta_hat = res.x  # estimate\n",
    "\n",
    "    # find out how many simulations were used\n",
    "    moms = moment_conditions_function(theta_hat,data_moments)\n",
    "    nsims = len(moms[0])  # will use in place of tau, assuming nobs=1 in the data\n",
    "\n",
    "    D = derivative(mean_conditions,theta_hat,dx=1e-10)  # Jacobian of moment conditions\n",
    "    DWD = D @ W @ D\n",
    "    if np.isscalar(DWD):\n",
    "        Sigma_hat = (1+1/nsims)/( DWD)  # using simple formula\n",
    "        stderr = np.sqrt(Sigma_hat)\n",
    "    else:\n",
    "        Sigma_hat = (1+1/nsims)*np.linalg.inv( DWD)  # using simple formula\n",
    "        stderr = np.sqrt(np.diag(Sigma_hat))\n",
    "    CI = [theta_hat-1.96*stderr,theta_hat+1.96*stderr]  # 1.96 confidence interval\n",
    "\n",
    "    print(f'MSM estimate       : {theta_hat:1.5f}')\n",
    "    print(f'StdErr of estimate : {stderr:1.5f}')\n",
    "    print(f'Confidence interval: ({CI[0]:1.5f},{CI[1]:1.5f})')\n",
    "\n",
    "    if plot:\n",
    "        # Plot criterion for visual inspection\n",
    "        xd = np.linspace(bracket[0],bracket[1],50)\n",
    "        yd = [criterion(b,W) for b in xd]\n",
    "        fig,ax = plt.subplots(figsize=(12,8))\n",
    "        ax.plot(xd,yd,color='r',label='MSM criterion function')\n",
    "        y1,y2 = ax.get_ylim()\n",
    "        ax.plot([theta_hat,theta_hat],[y1,y2],color='grey',label='MSM estimate')\n",
    "        ax.fill_between(x=CI,y1=y1,y2=y2,color='grey',alpha=0.25,label='1.96 confidence interval')\n",
    "        ax.legend()\n",
    "        ax.set_title('Criterion function and MSM estimate');\n",
    "\n",
    "    return theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "beta_hat = run_MSM()  # initial run with default identity weighting matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Second stage MSM\n",
    "moms = moment_conditions(beta_hat,data_moments_vec,seed=515)  # simulate a separate set of moment conditions\n",
    "S = np.cov(np.array(moms))                                    # variance-covariance matrix of moment conditions\n",
    "W1 = np.linalg.inv(S)                                         # unpdated weighting matrix\n",
    "beta_hat_2 = run_MSM(W=W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Further learning resources\n",
    "\n",
    "- 📖 Adda Cooper “Dynamic Economics” pp. 87-89  \n",
    "- Notebook by Richard W Evans on MSM [https://notes.quantecon.org/submission/5b3db2ceb9eab00015b89f93](https://notes.quantecon.org/submission/5b3db2ceb9eab00015b89f93)  \n",
    "- Example of MSM application to model the effects of the Australian age pension [https://doi.org/10.1016/j.jeconom.2020.01.023](https://doi.org/10.1016/j.jeconom.2020.01.023)  \n",
    "- Keane’s lecture on structural estimation at BFI at the University of Chicago [https://youtu.be/0hazaPBAYWE](https://youtu.be/0hazaPBAYWE)  \n",
    "- Popper’s falsification principle in under 2 min [https://youtu.be/wf-sGqBsWv4](https://youtu.be/wf-sGqBsWv4)  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1627474987.130928,
  "filename": "45_msm_estimation.rst",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Foundations of Computational Economics #45"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}